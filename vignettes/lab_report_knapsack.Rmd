---
title: "Advanced R Programming Lab 6 Report"
author: Connor Turner and Sachini Bambaranda
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{lab_report_knapsack}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(knapsack)
```

**Question 1: How much time does it take to run the brute force algorithm for n = 16 objects?**

It takes around five seconds for our brute force algorithm to go through 16 objects

```{r message = FALSE, warning = FALSE}
RNGversion(min(as.character(getRversion()),"3.5.3"))
set.seed(42, kind = "Mersenne-Twister", normal.kind = "Inversion")
n <- 16
knapsack_objects16 <-
data.frame(
w=sample(1:4000, size = n, replace = TRUE),
v=runif(n = n, 0, 10000)
)
```
```{r}
system.time(brute_force_knapsack(knapsack_objects16, 3500))
```

**Question 2: How much time does it takes to run the dynamic algorithm for n = 500 objects?**

It takes our dynamic algorithm roughly 60 seconds to go through 500 objects

```{r message = FALSE, warning = FALSE}
RNGversion(min(as.character(getRversion()),"3.5.3"))
set.seed(42, kind = "Mersenne-Twister", normal.kind = "Inversion")
n <- 500
knapsack_objects500 <-
data.frame(
w=sample(1:4000, size = n, replace = TRUE),
v=runif(n = n, 0, 10000)
)
```
```{r}
system.time(knapsack_dynamic(knapsack_objects500, 3500))
```

**Question 3: How much time does it takes to run the greedy heuristic algorithm for n = 1000000 objects?**

Our greedy algorithm goes through a million objects in about 0.15 seconds

```{r message = FALSE, warning = FALSE}
RNGversion(min(as.character(getRversion()),"3.5.3"))
set.seed(42, kind = "Mersenne-Twister", normal.kind = "Inversion")
n <- 1000000
knapsack_objects_million <-
data.frame(
w=sample(1:4000, size = n, replace = TRUE),
v=runif(n = n, 0, 10000)
)
```
```{r}
system.time(greedy_knapsack(knapsack_objects_million, 3500))
```

**Question 4: What performance gain could you get by using Rcpp and C++?**

The answer to this question depends on how many objects we are iterating through, and I am not sure why. As you can see in the code below, the C++ code performs about seven times faster than the regular R code when n = 8. But for some reason, once we get to n = 50, the performance gets to be about the same, and by n = 100 the C++ code performs nearly seven times *slower* than the R code. This doesn't make any sense to me, as the C++ code mirrors the nested for loop in knapsack_dynamic() almost to a T and the function is only being called once. Even after going through the code, taking out unnecessary steps, and streamlining as much as possible, the Rcpp code still couldn't seem to handle large data sets, and I for the life of me cannot figure out why. Perhaps it is something with Rcpp specifically, but there is nothing in the Rcpp function that I could see causing this slowdown - or at least this much of a slowdown. Any suggestions or advice would be appreciated.

```{r message = FALSE, warning = FALSE}
# When n ~ 10, the C++ code is significantly faster:
system.time(knapsack_dynamic(knapsack_objects[1:8,], 3500))
system.time(knapsack_dynamic(knapsack_objects[1:8,], 3500, fast = TRUE))

# When n ~ 50, performance is about the same:
system.time(knapsack_dynamic(knapsack_objects[1:50,], 3500))
system.time(knapsack_dynamic(knapsack_objects[1:50,], 3500, fast = TRUE))

# When n ~ 100, the C++ code is significantly slower:
system.time(knapsack_dynamic(knapsack_objects[1:100,], 3500))
system.time(knapsack_dynamic(knapsack_objects[1:100,], 3500, fast = TRUE))
```

**Question 5: What performance gain could you get by trying to improving your code?**

Two slight improvements we made came on the dynamic algorithm. Originally, we had named all the rows and columns in 'mat' to indicate the row number and weight. But this meant that when we were working on the for loops, we had to take the extra step to convert the index numbers to characters, otherwise it gave us an error. When we got rid of the row and column names and stopped having to convert to characters, it helped a bit with the speed. I also converted the columns in the data frame to vectors at the beginning of the dynamic function, and that improved things somewhat. Additionally, we received a sizable performance gain on the dynamic function by making some adjustments to the match() functions in the code. Essentially, instead of searching through every entry in mem, I adjusted it to only look through the first column where the values were stored. This lowered runtime significantly - particularly for a large number of objects.
